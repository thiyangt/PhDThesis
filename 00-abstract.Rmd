---
knit: "bookdown::render_book"
---

# Abstract {-}

Forecasting is a key activity for any business to operate efficiently. The dramatic increase in the availability of large collections of time series raises the need for developing reliable efficient and automatic algorithms for forecasting. This thesis presents three such algorithms for large-scale applications based on the meta-learning approach. The key idea behind the methodology is the use of a vector of features on each time series, measuring global characteristics of the series. The process starts with an offline phase: train a meta-learner to relate the features of time series to the performance of different forecast models using a large historical collection of time series. The online phase of generating forecasts involves only the calculation of a simple vector of features for any newly given time series and the application of a pre-trained meta-learner to produce the required forecasts. 


The first algorithm is FFORMS: Feature-based FORecast Model Selection. FFORMS builds a mapping that relates the features of  time series to the 'best' forecast model using a random forest. The process of generating forecasts involves the application of the best model for each series. This is a very fast and reliable approach. The FFORMS algorithm is evaluated using the time series from the M1, M3 and M4 competitions and is shown to yield accurate forecasts comparable to several benchmarks and other commonly used automatic approaches for time series forecasting. Furthermore, model-agnostic machine learning interpretability tools are used to explore what is happening under the hood of the FFORMS algorithm. In particular, the thesis explores *which* features are the most important for the choice of model selection; *where* they are most important, that is, for the overall classification process or, within specific class of models or a set of multiple classes of models; *how* these features link with the predicted outcome; and *when* and *how strongly* features interact with other features.  The results provide valuable insights into how different features and their interactions affect model selection.


The second algorithm, FFORMA (Feature-based FORecast Model Averaging) obtains weights for forecast combinations. The extreme gradient boost algorithm with a custom objective function is used to train a meta-model. The probabilities of each model being best are used as weights for computing a combination forecast. The FFORMA approach achieved second place in the recent M4  forecasting competition [@makridakis2018m4]. 

The third algorithm is FFORMPP (Feature-based FORecast Model Performance Prediction). The efficient Bayesian multivariate surface regression approach is used to model forecast error as a function of features calculated from the time series. FFORMPP allows rankings of models according to their relative forecast performance without calculating forecasts from all available models in the pool. Further, a feature-based time series simulation approach is used to obtain a diverse collection of time series to train the meta-learner.  In addition, the thesis attempts to visualise the relationships discovered by the meta-learning algorithm. The visualisation approach involves mapping each time series as a point in a two-dimensional instance space, given by the features. This helps to gain insights into why certain models perform better on certain types of time series. 



